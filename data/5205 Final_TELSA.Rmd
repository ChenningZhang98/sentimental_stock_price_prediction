---
title: "R Notebook"
output: html_notebook
---


library
```{r}
library(tidyquant)
library(quantmod)
library(tseries)
library(timeSeries)
library(forecast)
library(xts)
library(utils)
library(GGally)
library(devtools)
library(dplyr)
library(tidyr)
library(ggplot2)
library(httr)
library(stringr)
library(twitteR)
library(magrittr)
library(SentimentAnalysis)
library(gridExtra)
library(rtweet)
```


Stock Price Retrieval
```{r}
tsla <- tq_get('TSLA',
               from = "2021-04-06",
               to = "2021-04-14",
               get = "stock.prices")
```

Scrub Data
```{r}
as.data.frame(tsla)
#tsla <- subset(tsla, select = c(date,close))
tsla$date <- as.Date(tsla$date)
```

Tweets Retrieval - Tesla, and create CSV

```{r}

TSLA_4.6 = search_tweets("TSLA",n=1500,since= "2021-04-06",until = "2021-04-07",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.6 - 4.7.csv', row.names =FALSE)

TSLA_4.7 = search_tweets("TSLA",n=1500,since= "2021-04-07",until = "2021-04-08",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.7 - 4.8.csv', row.names =FALSE)

TSLA_4.8 = search_tweets("TSLA",n=1500,since= "2021-04-08",until = "2021-04-09",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.8 - 4.9.csv', row.names =FALSE)

TSLA_4.9 = search_tweets("TSLA",n=1500,since= "2021-04-09",until = "2021-04-10",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.9 - 4.10.csv', row.names =FALSE)

TSLA_4.10 = search_tweets("TSLA",n=1500,since= "2021-04-10",until = "2021-04-11",include_rts = F, lang ='en')
#f<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.10 - 4.11.csv', row.names =FALSE)

TSLA_4.11 = search_tweets("TSLA",n=1500,since= "2021-04-11",until = "2021-04-12",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.11 - 4.12.csv', row.names =FALSE)

TSLA_4.12 = search_tweets("TSLA",n=1500,since= "2021-04-12",until = "2021-04-13",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.12 - 4.13.csv', row.names =FALSE)

TSLA_4.13 = search_tweets("TSLA",n=1500,since= "2021-04-13",until = "2021-04-14",include_rts = F, lang ='en')
#df<- apply(TSLA,2,as.character)
#write.csv(df,'TSLA_tweets 4.13 - 4.14.csv', row.names =FALSE)


TSLA = rbind(TSLA_4.6,TSLA_4.7,TSLA_4.8,TSLA_4.9,TSLA_4.10,TSLA_4.11,TSLA_4.12,TSLA_4.13)


##create dataframe
TSLA <- as.data.frame(TSLA)

```
Tweets Cleaning for Tesla between 4.6 - 4.13 
```{r}
x <- TSLA

x$text <- enc2native(x$text)


#Clean text
x$text <- gsub("^[[:space:]]*","",x$text) # Remove leading whitespaces
x$text <- gsub("[[:space:]]*$","",x$text) # Remove trailing whitespaces
x$text <- gsub(" +"," ",x$text) #Remove extra whitespaces
x$text <- gsub("'", "%%", x$text) #Replace apostrophes with %%
x$text <- iconv(x$text, "latin1", "ASCII", sub="") # Remove emojis
x$text <- gsub("<(.*)>", "", x$text) #Remove Unicodes like <U+A>
x$text <- gsub("\\ \\. ", " ", x$text) #Replace orphaned fullstops with space
x$text <- gsub("  ", " ", x$text) #Replace double space with single space
x$text <- gsub("%%", "\'", x$text) #Change %% back to apostrophes
x$text <- gsub("https(.*)*$", "", x$text) #Remove tweet URL
x$text <- gsub("\\n", "-", x$text) #Replace line breaks with "-"
x$text <- gsub("--", "-", x$text) #Remove double "-" from double line breaks
x$text <- gsub("&amp;", "&", x$text) #Fix ampersand &
x$text[x$text == " "] <- "<no text>"

cleanTweets <- x %>% 
               select("text")
```
Look for daily mean tweets sentiment for Tesla
```{r}
library(dplyr)

#Analyze sentiment
sentiment <- analyzeSentiment(cleanTweets)
#Extract dictionary-based sentiment according to the QDAP dictionary
sentiment2 <- sentiment$SentimentQDAP
#View sentiment direction (i.e. positive, neutral and negative)
sentiment3 <- convertToDirection(sentiment$SentimentQDAP)

#Extract and convert 'date' column
date <- x$created
date <- str_extract(date, "\\d{4}-\\d{2}-\\d{2}")
date <- as.Date(date)
date <- as.Date(date, format = "%m/%d/%y")

#Create new dataframe with desired columns
df <- cbind(cleanTweets, sentiment2, sentiment3, date)
#Remove rows with NA
df <- df[complete.cases(df), ]


#Calculate the average of daily sentiment score
df2 <- df %>% 
       group_by(date) %>%
       summarize(meanSentiment = mean(sentiment2, na.rm=TRUE))


DT::datatable(df2, editable = TRUE)

```
```{r}
#Get frquency of each sentiment i.e. positive, neutral, and negative  
freq <- df %>% 
        group_by(date,sentiment3) %>% 
        summarise(Freq=n())

#Convert data from long to wide
freq2 <- freq %>% 
         spread(key = sentiment3, value = Freq)

DT::datatable(freq2, editable = TRUE)


ggplot() + 
  geom_bar(mapping = aes(x = freq$date, y = freq$Freq, fill = freq$sentiment3), stat = "identity") +
  ylab('Sentiment Frequency') +
  xlab('Date')
```
```{r}
#Calculate z-Scores of Tesla closing stock prices
mu <- mean(tsla$close)
sd <- sd(tsla$close)
tsla2 <- tsla %>% 
         mutate(zScore = (tsla$close-mu)/sd)

#Plot mean sentiment scores
p1 <- ggplot(data=df2, aes(x=date,y=meanSentiment, group=1)) +
  geom_line()+
  geom_point() +
  ylab("Mean Twitter Sentiment Score")

#plot Amazon Nasdaq z-score prices
p2 <- ggplot(data=tsla2, aes(x=date,y=zScore, group=1)) +
  geom_line()+
  geom_point() +
  ylab("Z-Score of closing stock price")
  scale_x_date(date_breaks = "1 day", 
                 limits = as.Date(c('2021-04-06','2021-04-08')))
```

```{r}
plot1 <- p1
plot2 <- p2
grid.arrange(plot1, plot2, nrow=2)
```

Z-score closing stock price
```{r}
#Plot both data on same plot
ggplot() + 
  geom_line(mapping = aes(x = tsla2$date, y = tsla2$zScore), size = 1) + 
  geom_line(mapping = aes(x = df2$date, y = df2$meanSentiment*20), size = 1, color = "blue") +
  scale_x_date(name = "Date", labels = NULL) +
  scale_y_continuous(name = "z-Score of Closing Stock Price", 
  #Scale 2nd y-axis by factor of 20
  sec.axis = sec_axis(~./20, name = "Sentiment Score")) + 
  theme(
      axis.title.y = element_text(color = "grey"),
      axis.title.y.right = element_text(color = "blue"))
```


```{r}
#Plot both data on same plot
#Shift stock prices back one day
plot(df2$date,df2$meanSentiment, type="l", col="red3",  xlab='Date', ylab='Mean Sentiment Score')

par(new=TRUE)

plot(tsla2$date,tsla2$zScore, type="l", axes=F, xlab=NA, ylab=NA, col="blue")
axis(side = 4)
mtext(side = 4, line = 3, 'Closing Stock Price z-Score')
legend("topright",
       legend=c("Mean Sentiment Score"),
       lty=c(1,0), col=c("red3"))
```

##################Correlation##################
```{r}
####Correlation Analysis 
tsla$date <- as.Date(tsla$date, format = "%Y-%m-%d")
tsla$date <- as.Date(strptime(tsla$date, format = "%Y-%m-%d"))

# Now we create a new df with the above sentiment analysis merged df plus
# the stock prices index Be carefull to have the same dates to both
require(dplyr)
tweets_plus_stock <- left_join(df, tsla, by = "date")

# create a new df in order to remove the rows that we dont have adjusted
# closing entry. (adj closing is the closing price of the share that
# corresponding date)
weekday_tweets_plus_stock <- tweets_plus_stock
weekday_tweets_plus_stock <- subset(tweets_plus_stock, !is.na(close))

# We add new features fields (as 0,1 factor) to mark tweets as positive or
# negative or neutral
weekday_tweets_plus_stock$positive <- as.numeric(weekday_tweets_plus_stock$sentiment2 > 0)
weekday_tweets_plus_stock$negative <- as.numeric(weekday_tweets_plus_stock$sentiment2 < 0)
weekday_tweets_plus_stock$neutral <- as.numeric(weekday_tweets_plus_stock$sentiment2 == 0)

# We create a new df with sums. From one row per tweet - to one row per day.
# Showing the sum positives, negatives and newtral tweets per day
require(plyr)
tweets_plus_stock_df <- ddply(weekday_tweets_plus_stock, c("date", "high", "low", "close"), plyr::summarise, pos.count = sum(positive), neg.count = sum(negative),neu.count = sum(neutral))

# We add a new feature with the sum tweets of the 3 sentiment categories
tweets_plus_stock_df$sum.count <- tweets_plus_stock_df$pos.count + tweets_plus_stock_df$neg.count + tweets_plus_stock_df$neu.count

# We calculate the percentage of negative tweets for each day, and add it as
# a new feature
tweets_plus_stock_df$percentage.negatives <- round((tweets_plus_stock_df$neg.count/tweets_plus_stock_df$sum.count) * 
                                                     100)
```


```{r}
##Correlation tsla closing stock price vs Negative Tweets Sentiments
require(GGally)

###negative percentage
ggpairs(tweets_plus_stock_df, columns = c(9, 4), ggplot2::aes(color = "red"), 
        title = "Correlation: Closing Stock Price VS Tweets Sentiment", upper = list(continuous = wrap("cor", size = 10)), lower = list(continuous = "smooth"))
```


```{r}
###positive percentage
ggpairs(tweets_plus_stock_df, columns = c(9, 4), ggplot2::aes(color = "red"), 
        title = "Correlation: Closing Stock Price VS Tweets Sentiment", upper = list(continuous = wrap("cor", size = 10)), lower = list(continuous = "smooth"))
```


```{r}
##Regression model percentage of negative tweets vs stock closing price
library(stats)

cor(tweets_plus_stock_df$percentage.negative, tweets_plus_stock_df$close, 
    use = "complete")
glm_model_neg <- glm(tweets_plus_stock_df$close ~ tweets_plus_stock_df$percentage.negative)
summary(glm_model_neg)
require(lattice)

xyplot(tweets_plus_stock_df$close ~ tweets_plus_stock_df$percentage.negatives, 
       grid = TRUE, type = c("p", "r"), col.line = "red", lwd = 3, ylab = "Daily Change of Tesla Share Price in $", 
       xlab = "% of Negative Tweets", main = "% of negative Tweets vs Daily
       Tesla Share Price")
```


```{r}
tweets_plus_stock_df$percentage.positives <- round((tweets_plus_stock_df$pos.count/tweets_plus_stock_df$sum.count) * 
                                                     100)
```


```{r}
##Regression model percentage of positive tweets vs stock closing price
library(stats)
cor(tweets_plus_stock_df$percentage.positives, tweets_plus_stock_df$close, 
    use = "complete")
glm_model_pos <- glm(tweets_plus_stock_df$close ~ tweets_plus_stock_df$percentage.positives)
summary(glm_model_pos)
require(lattice)
xyplot(tweets_plus_stock_df$close ~ tweets_plus_stock_df$percentage.positives, 
       grid = TRUE, type = c("p", "r"), col.line = "blue", lwd = 3, ylab = "Daily Change of Tesla Share Price in $", 
       xlab = "% of Positive Tweets", main = "% of positive Tweets vs Daily
       Tesla Share Price")
##############################################




```











